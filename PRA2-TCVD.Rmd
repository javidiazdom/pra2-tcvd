---
title: "PRA2-TCVD"
author: "Javier Díaz Domínguez"
date: "29/12/2021"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = 'data')
```


<center> 
  <h1> Práctica 2: Limpieza y validación de los datos </h1>
  <h2> Javier Díaz Domínguez </h2>
  <h3> 30 de diciembre de 2021 </h3>
</center>

# 1. Detalles de la actividad

## 1.1 Descripción

La práctica 3 consiste en la realización de un caso práctico de análisis y tratamiento de un conjunto de datos, con el objetivo principal de identificar los datos relevantes y el tratamiento necesario para llevar a cabo un proyecto analítico.

## 1.2 Objetivos

Los objetivos concretos de esta práctica son:

- Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de
problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o
multidisciplinares

- Saber identificar los *datos relevantes* y los *tratamientos necesarios* (integración,
limpieza y validación) para llevar a cabo un proyecto analítico.

- Aprender a analizar los datos adecuadamente para abordar la información contenida en
los datos.

- Identificar la mejor representación de los resultados para aportar conclusiones sobre el
problema planteado en el proceso analítico.

- Actuar con los *principios éticos* y *legales* relacionados con la manipulación de datos en
función del ámbito de aplicación.

- Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un
modo que tendrá que ser en gran medida autodirigido o autónomo.

- Desarrollar la *capacidad de búsqueda, gestión y uso de información* y recursos en el
ámbito de la ciencia de datos.


## 1.3 Competencias

Así, las competencias del Máster en _Data Science_ que se desarrollan son:

- Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación
y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.

- Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración,
transformación, limpieza y validación) para su posterior análisis.


# 2. Resolución

## 2.1 Descripción del dataset

Para esta práctica, se ha seleccionado el conjunto de datos denominado Covid-19 Global Dataset, que contiene información sobre los casos de Covid confirmados diariamente para 218 países al rededor del mundo. Este _dataset_ ha sido tomado de [Kaggle](https://www.kaggle.com/josephassaker/covid19-global-dataset). Está constituido por 7 columnasy 145221 registros, que contienen datos sobre los casos de covid confirmados durante 657 días para los 218 países excepto china, que tiene registros desde casi un més antes y cuenta con 681 días registrados.  Los campos son los siguientes

- *date*: fecha en la que se realizó la observación
- *country*: país al que corresponde la información de cada regitro
- *cumulative_total_cases*: la acumulación de positivos hasta la fecha, para el país del registro.
- *daily_new_cases*: nuevos casos registrados el día de la observación, para el país del registro.
- *active_cases*: número de casos activos en la fecha y para el país del registro.
- *cumulative_total_deaths*: acumulación de fallecimientos hasta la fecha, para el país del registro.
- *daily_new_deaths*: nuevos fallecimientos registrados el día de la observación.

Además, para la resolución del apartado 2.5.2 se ha incluido un dataset con información sobre la población de los países. Este datases ha sido extraído de [The World Bank](https://data.worldbank.org/indicator/SP.POP.TOTL), y su anatomía es la siguiente:

- *LocID*: identificador único del país.
- *Location*: nombre del país.
- *VarID*: Identificador de la variante
- *Variant*: Nombre de la variante
- *Time*: Year
- *MidPeriod*: Mitad del año
- *PopMale*: Población masculina
- *PopFemale*: Población femenina
- *PopTotal*: Población total
- *PopDensity*: Densidad de población

## 2.2. Importancia y objetivos de los análisis 

Haciendo uso de la información contenida en este conjunto de datos, se pueden obtener conclusiones varias sobre la gestión de los diferentes países, identificar patrones de cara a prevenir nuevas olas de contagios o entender qué países son los que mejor han gestionado la pandemia para identificar las medidas que han tomado y considerarlas como efectivas.

El análisis de esta información puede ofrecer a las instituciones gubernamentales nuevas perspectivas de cara a la gestión de la pandemia, tanto para la prevención de nuevas oleadas como para la valoración de la gestión realizada.

## 2.3 Limpieza de los datos

```{r}
# Lectura del dataset
cvdf <- read.csv("worldometer_coronavirus_daily_data.csv")
popdf <- read.csv("WPP2019_TotalPopulationBySex.csv")
head(cvdf)
head(popdf)
```

```{r}
# Tipo de datos de cada una de las columnas
sapply(cvdf, function(x) class(x))
sapply(popdf, function(x) class(x))
```
Se observa que las columna `date` no ha sido identificada correctamente por R como de tipo date, por lo que se procede a corregirlo.

```{r}
cvdf$date <- as.Date(cvdf$date)
```




### 2.3.1 Selección de los datos de interés

Teniendo en cuenta los objetivos del analisis todas las columnas del dataset de casos COVID son relevantes, por lo que no es necesaria ninguna selección.

Sin embargo, la reducción del tamaño del dataset de la población mundial es posible, ya que sólo es necesaria la última cifra registrada para el total de población. Además, las columnas de población femenina y masculina no son relevantes de cara a este estudio, además de que son las columnas que presentan valores vacíos.

```{r}
### Selección del último registro para cada país
popdf <- popdf[popdf$Time == '2019',]
### Criba de columnas innecesarias
popdf <- subset(popdf, select = c("Location", "PopTotal"))
```

Además, se identifica que la escala en la que se expresa la población es difernte a la de las cifras de covid, por lo que se procede a su normalización.

```{r}
popdf$PopTotal <- popdf$PopTotal * 1000
```



### 2.3.2 Ceros y elementos vacíos

En este dataset, los elementos vacíos representan que no se tenía información para ese día y ese país, y solo se encuentran en las columnas que contienen información numérica.

```{r}
colSums(is.na(cvdf))
colSums(is.na(popdf))
```

Los NA's son valores equivalentes a 0, por lo que se procederá sustituyendo los valores `Not Available` por 0. 

```{r}
cvdf[is.na(cvdf)] <- 0
colSums(is.na(cvdf))
```



### 2.3.3. Valores extremos

Los valores extremos o _outliers_ son aquellos datos que se encuentran muy alejados de la distribución normal de una variable o población. Se procede con su detección mediante la representación de diagramas de caja para cada una de las variables numéricas. Además, con el diagrama de caja podremos obtener información adicional sobre la distribución de las variables.

```{r}
boxplot(cvdf$cumulative_total_cases)
```

Analizando el gráfico resultante, observamos que existe una gran cantidad de _outliers_. Teniendo en cuenta que se trata de una variable acumulativa y que se recogen datos de países con poblaciones tan distantes (como por ejemplo las), la aparición de estos valores extremos es normal. Estos valores pertenecerán a los países con mayor número de habitantes, como India, China o Estados Unidos.

```{r}
boxplot(cvdf$daily_new_cases, main="Nuevos casos diarios")
boxplot(cvdf$active_cases,main="Casos activos")
boxplot(cvdf$cumulative_total_deaths, main="Acumulación de muertes")
boxplot(cvdf$daily_new_deaths, main="Muertes diarias")
```
Como vemos, esta tendencia a tener una gran cantidad de _outliers_ se repite para todas las variables del conjunto de datos, con la misma explicación. Además, la gestión de la pandemia ha sido considerablemente variable en los diferentes países, lo que refleja una gran varianza en las cifras de casos y muertes diarios y totales.


### 2.3.4. Exportación de los datos preprocesados

Para completar la fase de preprocesamiento de los datos, se realiza la exportación a un fichero CSV del conjunto de datos resultante.

```{r}
write.csv(cvdf, "covid_daily_clean.csv")
write.csv(popdf, "global_pop.csv")
```

## 2.4. Análisis de los datos

### 2.4.1. Selección de los grupos de datos a analizar

Dada la naturaleza de la información con la que se trabaja, la principal agrupación selección y agrupación de los datos a realizar es la división de la información por países. Esto nos permitirá realizar visualizaciones de las curvas de contagios para cada uno de los países. 

```{r}
cv_by_country <- split(cvdf, cvdf$country)
```


### 2.4.2 Comprobación de la normalidad y homogeneidad de la varianza

El siguiente paso es la comprobación de la normalidad de las distribuciones de las diferentes variables cuantitativas que componen el conjunto de datos.
Para ello, se implementa una función que indicará cuales de las variables siguen una distribución normal según el test de Saphiro-Wilk con un nivel de significación del 0.05.

```{r}
library("stats")
alpha = 0.05
col.names = colnames(cvdf)
cat("Variables que no siguen una distribución normal: \n")
for (i in 1:ncol(cvdf)) {
  if(is.integer(cvdf[,i]) | is.numeric(cvdf[,i])) {
    if(shapiro.test(sample(cvdf[,i], 5000))$p.value < alpha) {
      cat(col.names[i])
      cat(", ")
    }
  }
}
```

Del análisis de normalidad de las diferentes variables, se extrae la conclusión de que *ninguna de ellas sigue una distribución normal*.

Confirmamos esta afirmación mediante la visualización gráfica de la variable `active_cases`:

```{r}
plot(density(cvdf$active_cases), xlim = c(0, 100000))
```

Como muestra esta gráfica, se trata de una variable con una varianza muy grande (`r var(cvdf$active_cases)`).

El siguiente paso consistirá en el estudio de la homogeneidad de varianzas, mediante la aplicación del *test de Fligner-Killeen*.  Se estudiará la homogeneidad en cuanto a los casos activos agrupados por países. La hipótesis nula del siguiente test es que las varianzas son iguales.

```{r}
library("stats")
fligner.test(active_cases ~ country, data = cvdf)
```
Dado que el `p-value` es menor a $\alpha = 0.05$, se rechaza la hipótesis nula, es decir, no podemos afirmar que las varianzas son homogéneas para los casos activos por país.

## 2.5. Pruebas estadísticas

### 2.5.2. Existe una relación entre el número final de casos totales (a día 02 de diciembre de 2021) y la población de los países?

En primer lugar, se realiza la selección de los últimos datos registrados.

```{r}
latest_cv_data <- cvdf[cvdf$date == max(cvdf$date),]
colnames(latest_cv_data)[2] <- "Location"
```

Lo siguiente es hacer un _right join_ de los dos conjuntos de datos en la columna que coinciden, la que contiene el nombre del país.

```{r}
cv_pop_df <- merge(x = latest_cv_data, y = popdf , by = "Location", all.x=TRUE)
```

Debido a que la notación puede no ser la misma, es posible que resulten valores nulos. Por ello, para estudiar la relación entre las dos variables sólo se tendrán en cuenta las filas cuyos valores de población total no sean nulos. Además se almacena el dataset creado.

```{r}
cv_pop_df <- cv_pop_df[!is.na(cv_pop_df$PopTotal),]
write.csv(cv_pop_df, "covid_population_data.csv")
```

Se procede con el estudio de relación entre las variables

```{r}
cor.test(cv_pop_df$cumulative_total_cases, cv_pop_df$PopTotal, method="pearson")
```

El resultado del estudio de correlación entre las dos variables arroja un valor estimado de 0.5931 Esto indica que existe cierta relación entre las dos variables pero que no se puede aceptar la hipótesis nula, por lo que no podemos afirmar que la relación real es igual a 0. Para corroborarlo, se confecciona un gráfico donde se puede apreciar visualmente la relación entre las variables.

```{r}
cv_pop_df <- cv_pop_df[with(cv_pop_df, order(cv_pop_df$PopTotal)),]
graph_data <- cv_pop_df[sample(nrow(cv_pop_df), 14),]
plot(factor(graph_data$Location), graph_data$PopTotal, log='y')
points(factor(graph_data$Location),  graph_data$cumulative_total_cases) 
```

La representación se realiza en escala logarítmica para paliar la gran diferencia de escala entre las variables. En ella podemos observar como, efectivamente, existe una cierta relación entre las dos variables, y es que los países con una población mayor tienen un mayor número de muertes acumuladas. 

Sin embargo, la ejecución del test de correlación permite sacar una conclusión reveladora: los países con más habitantes no están revocados al inevitable destino de tener un mayor número de muertes, es decir, que existe un factor ajeno (que posiblemente sea la toma de medidas) al total de población que permite reducir la fatalidad del virus.

### 2.5.3. Para dos países con poblaciones totales similares, ¿existe diferencia entre los casos diarios?

La verdadera pregunta en este caso es, para los países elegidos, cuál de los dos ha tenido una mejor gestión (ha mantenido el número de nuevos casos diarios controlado). Para ello, tomamos los datos del Reino Unido y Francia, que cuentan con poblaciones similares: `r cv_pop_df[cv_pop_df$Location == 'France',]$PopTotal` para Francia y `r popdf[popdf$Location == 'United Kingdom',]$PopTotal`. La población de Reino Unido es un `r (popdf[popdf$Location == 'United Kingdom',]$PopTotal / cv_pop_df[cv_pop_df$Location == 'France',]$PopTotal - 1)* 100`% mayor que la de Francia, por lo que si los dos países hubieran tenido una gestión de la crisis similar, es de esperar que las cifras de casos diarios en cómputo global estén a la par.

Por lo tanto, se plantea el siguiente contraste de hipótesis unilateral atendiendo a la hipótesis alternativa

$$
H_0:\mu_0-\mu_1=0\\ 
H_1:\mu_0-\mu_1>0
$$
donde $\mu_0$ es la media de los casos diarios del Reino Unido durante la pandemia y $\mu_1$ es la media de casos diarios de Francia durante la pandemia. Se realiza la segmentación de datos

```{r}
uk_daily_cases <- cvdf[cvdf$country == 'UK',]$active_cases
fr_daily_cases <- cvdf[cvdf$country == 'France',]$active_cases
```

y se procede con la ejecución del test

```{r}
t.test(uk_daily_cases, fr_daily_cases, alternative = "greater")
```
La ejecución de este test indica que no es posible aceptar la hipótesis nula, por lo que es posible concluir que la media de casos activos en Francia ha sido menor a pesar de tener la misma población que el Reino Unido, *su gestión de la crisis sanitaria ha sido mejor*.

### 2.5.4. Modelo de regresión lineal

Para este último apartado, se propone la elaboración de un modelo de regresión lineal que permita obtener una predicción del número acumulado de fallecidos para fechas futuras y para un país en concreto. En este caso, se toma España. Se realiza la segmentación de los datos y se calcula la matriz de correlación.

```{r}
spain_data <- cvdf[cvdf$country == 'Spain',]
spain_data$date <- as.numeric(spain_data$date)
library("corrplot")
corrplot(cor(spain_data[,c(1,3,4,5,6,7)]))
```

La matriz de correlación indica, que para la variable cumulative_total_deaths, las variables con mayor correlación son `date` y `cumulative_total_cases`. Por lo tanto, se elaboran dos modelos, y se escoge como óptimo el que cuente con mayor índice de correlación $(R^2)$. 

```{r}
model1 <- lm(cumulative_total_deaths ~ date, data=spain_data)
model2 <- lm(cumulative_total_deaths ~ date + cumulative_total_cases, data=spain_data)

summary(model1)$r.squared
summary(model2)$r.squared
```
El valor del coeficiente de determinación del segundo modelo es mejor que el del primero, por lo que se toma como óptimo y se realiza una predicción con el para el día 31-12-2021 y con los [datos oficiales](https://www.mscbs.gob.es/profesionales/saludPublica/ccayes/alertasActual/nCov/documentos/Actualizacion_533_COVID-19.pdf)

```{r}
predict_input <- data.frame(
  date = as.numeric(as.Date("2021-12-31")),
  cumulative_total_cases = 6294745
)
predict(model2, predict_input)
```

Según el ministerio de sanidad, la cifra de fallecidos a día 31 de diciembre de 2021 era de 89.405: la predicción generada por el modelo no es precisa. 

Este error se debe a que existen factores determinantes en el número total de muertos, como el porcentaje de vacunados, que no se han incluido en el modelo, por lo que el modelo no tiene la información suficiente para realizar una predicción precisa. 

## 2.6. Conclusiones

El conjunto de datos ha permitido un análisis bastante interesante sobre los diferentes indicadores clave de la pandemia global causada por el Covid-19: los casos activos, el total de muertes y el total de casos. Además, gracias a la inclusión de información externa al dataset, como la población de los diferentes países, ha sido posible extraer conclusiones adicionales también muy interesantes, que permiten realizar afirmaciónes sobre la gestión de la pandemia al rededor del mundo basadas en datos oficiales y comprobados. 

Todo este análisis fue posible gracias a la fase de tratamiento y análisis previo, en la que se identifican las caraterísticas principales de los conjuntos de datos empleados en la práctica, para posteriormente realizar las acciones que se han considerado necesarias de cara a la ejecución del análisis estadístico.

Principalmente con este análisis se ha descubierto que *la población de un país* y su *éxito en la gestión de la pandemia* están ciertamente relacionados, pero no lo suficiente; que la gestión del la pandemia de Francia ha sido mejor que la de Inglaterra; y por último se ha elaborado un modelo de regresión lineal que permite obtener predicciones sobre *las cifras de muertes acumuladas* en España en base al día y a la cifra de casos acumulados.

# 3. Recursos

- Mireia, C., Diego, P., Laia, S.(2019). _Introducción a la limpieza y análisis de los datos._ Material UOC.

- Mireia, C., Diego, P., Laia, S.(2019). _Introducción al ciclo de vida de los datos_. Material UOC.
